### 关于多核架构下内存分配技术的一些调研：

#### 多核CPU的优点：

##### 网络设备上传统CPU的特点：

从处理器的报文转发能力上看：

 通用 CPU < 嵌入式 CPU < 网络处理器 < ASIC

 而从四到七层业务处理能力上看：

 ASIC < 嵌入式 CPU < 网络处理器 < 通用 CPU 

各种处理器各有优缺点，多核处理器（多核 CPU）就是朝着理想处理器方向努力应运而生的，器是在目前芯片功耗限制下，能找到的最好的提升芯片性能的方法。

##### 而在多核架构下，网络操作系统内存管理以及多核多系统共享内存的管理与传统CPU相比均会有所调整。



#### 多核技术特征：

​        处理器中有多个通用的CPU集中而成，每个处理单元成为一个Core，每个 Core 有一套独立的取指、指令 解析、指令执行和逻辑运算单元，拥有自己独立的 L1 Data Cache 和 L1 Instruction Cache。 多核处理器中的多个 Core 共享 L2 Cache 或分别具有独立的 L2 Cache， 各个 Core 完全并发的执行指令，系统中的 L1 Cache 以及 L2 Cache 一致性通常 由硬件保证，软件不需要做特殊处理。 

​        为了充分利用系统资源，部分多核处理器的每一个 Core 又被划分 为多个虚拟处理器，这些虚拟处理器拥有各自独立的一套寄存器，共享所属 Core 的 L1 Data Cache 和 L1 Instruction Cache，以时分复用的方式共享 Core 的取指、 指令解析、指令执行和逻辑运算单元，每一个虚拟处理器（VCPU）被称为一个 Thread，属于同一个 Core 的 Thread 的调度由硬件自动完成，对于应用模块来说， 一个 Thread 就像一个独立的 CPU 一样运行。 

​       每个Core之间通过一种名为核间消息的异步传输机制来通信。

​        系统中集成了一些专业硬件加速单元（如加密/解密引擎，压缩/解压缩引擎 等），软件可以利用这些硬件单元加速业务的处理。 



#### 多核架构下值得注意的新特点：

​          在对临界资源的保护上，由于各个Core/Thread并发处理的特点，原有的信号量和关中断方式已经无法保证互斥访问，所以一般使用自旋锁来进行临界资源的保护。

​           使用原则：加锁范围应尽量小，加锁期间不能发生任务切换，有时需和开关 中断配合使用，需要防止死锁； 

####  内存镜像技术  

​        内存镜像机制要求每一个 Core/Thread 保留一份临界资源镜像，每个核只对 自己保留的镜像进行访问和修改，在 修 改 的 时 候 发 消 息 通 知 所 有 拥 有 该 资源镜像 的其他 Core/Thread，其他 Core/Thread 在接收到消息后进行同步处理，以保证所 有的 Core/Thread 感知到临界资源的更新，由于每一个 Core/Thread 访问的资源只 有自己会修改，在访问的时候不需要加自旋锁保护。 





#### 多核系统内存管理的新特点

如内存访问冲突，共享 Cache 失效，核间碎片等。

##### 互斥访问 

1、硬件原子操作；

2、自旋锁。

##### 共享 Cache 失效 

当分别属于不同线程的对象共享 Cache Line 且这些线程分布在拥有独立 Cache 的不同的核上时，当一个核中的对象发生变化时，与 该 对 象 处 于 同一 Cache Line 的对象缓存相应失效。

#####  核间碎片

多核系统每个核都拥有自己的 Cache，由于一定的分配策略，一个线程释放 的内存不能被另一个线程使用，这样就会形成许多外部内存碎片





###  常见多核多线程分配算法 



**Hoard**：Hoard 为每个核设置一个缓冲区（Per-processror heaps），每个核的缓 冲区只有该核的线程有权访问，此外还设立一个所有核均可以访问的全局堆 （global heap，heap 0） ，Hoard 对小对象通过超级块（Superblock）来进行管理。 每个超级块由一些大小相同的内存块组成，通过一个链表来维护该超级块内的空 闲内存块。所有超级块大小相同，是系统物理内存页大小的整数倍。Hoard 按大 小把内存块分为若干类型，同时根据内部内存块的类型分为不同类型的超级块。
 当核 i 上的某个线程有内存分配需求时，对该核的缓冲区（Heap i）加锁， 先找到与所需内存大小最接近的内存块类型，从有空闲块的该类型超级块中分配 一个内存块来使用，如果此时该类型的超级块均没有空闲内存块，从全局堆（Heap 0）中分配一个超级块供（Heap i）使用；如果此时不论该核缓冲区（Heap i）还 是全局缓冲区（Heap 0）均没有超级块可用，从系统内存区中分配一个超级块放 到该核的缓冲区（Heap i）上，从此超级块中取出一个内存块既可使用。当有内 存块释放时，通过内存块头上的指针找到所属的超级块，首先对该超级块加锁， 然后对此超级块所在的核缓冲区加锁，把该内存块释放到所属超级块中。当该核 缓冲区上的空闲内存块达到一定“水位”时，遍历该核缓冲区中的超级块，当某 个超级块上的空闲内存达到一定“水位”时，释放一部分内存块到全局堆中。操 作完成后对该核缓冲区解锁。 



**Streamflow**：在 Streamflow中，每个线程设立一个线程本地堆，线程从对应 的线程堆上分配，这样多个线程上的内存分配可以独立完成，不需要同步，同步 发生在线程本地堆上没有足够的内存来满足分配需求，或 者 是 一 个 对 象 被 不是分 配该对象的线程所释放时。 每个线程本地堆由一些页组构成，每个页组由一些相同大小的分片组成，满 足一定大小范围（Object Class） 的内存分配需求，相同类型的页组通过双向链 表相连。 Streamflow在内存分配时内存对象没有对象头，它是通过一个全局表的形式 记录所有物理内存页与页组的对应关系，当内存释放时，通过该全局表查到释放 内存所属的页组，即可对其进行释放。 Streamflow内存对象分配和释放过程大致与 Hoard 相同。 





**PtMalloc**：PtMalloc 通过多个线程堆来减少内存访问时的冲突，但是线程堆 与线程之间不是一一对应的，而是动态变化的，线程每次对内存进行操作时，首 先尝试从上一次使用的线程堆中进行分配，若该线程堆此时正在被其他线程使 用，该线程就被指定通过某个此时不在被使用的线程堆来进行分配，若此时所有 的线程堆均被使用，内存分配程序就分配一个新的线程堆供其使用。 

